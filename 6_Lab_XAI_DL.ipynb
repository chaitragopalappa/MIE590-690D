{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMn023mqAkIrqtH1bPSCiHx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaitragopalappa/MIE590-690D/blob/main/6_Lab_XAI_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Python libraries for XAI**\n",
        "* CAPTUM - this is a dedicated PyTorch library for XAI methods, is the most comprehensive library, and actively maintained.\n",
        "  * [PyTorch library - CAPTUM](https://captum.ai/docs/attribution_algorithms)  \n",
        "  * [Journal article - CAPTUM](https://arxiv.org/pdf/2009.07896)\n",
        "\n",
        "* Other Python libraries  \n",
        "  * [SHAP](https://github.com/shap/shap#deep-learning-example-with-gradientexplainer-tensorflowkeraspytorch-models)  \n",
        "\n",
        "  * [TF-Explain](https://pypi.org/project/tf-explain/) [GitHUB](https://github.com/sicara/tf-explain)  \n",
        "  * [iNNvestigate](https://github.com/albermax/innvestigate?tab=readme-ov-file)\n",
        "\n",
        "* AutoML (automated machine learning) Platforms\n",
        "  * [H2O.AI](https://h2o.ai/company/ai-4-good/): automates the entire datascience workflow including IML techniques. Similar to  standalone software.\n",
        "  \n"
      ],
      "metadata": {
        "id": "2la-_KGfqqJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Review the different methods for interpretability"
      ],
      "metadata": {
        "id": "yy-0W9UV8Uk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Attribution methods for tabular data:\n",
        "  * FFNN using California House Prices:\n",
        "https://captum.ai/tutorials/House_Prices_Regression_Interpret  \n",
        "[GITHUB](https://github.com/pytorch/captum/blob/master/tutorials/House_Prices_Regression_Interpret.ipynb )\n",
        "* [CAPTUM Titanic data analysis: Integrated gradient, layer conductance, neuron conductance](https://github.com/meta-pytorch/captum/blob/master/tutorials/Titanic_Basic_Interpret.ipynb)\n"
      ],
      "metadata": {
        "id": "1PNg-oud5OHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Attribution methods for image data in CNN\n",
        "* [CAPTUM: pretained ResNet, VGG](https://github.com/meta-pytorch/captum/blob/master/tutorials/TorchVision_Interpret.ipynb): Apply Integrated Gradients (w/ and w/o noise tunnel), GradientShap, Occlusion, and LRP on pretrained deep learning models (ResNet, VGG).\n",
        "\n"
      ],
      "metadata": {
        "id": "N7FDDoOG5qv4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Detecting concepts: TCAV\n",
        "  * TCAV original library (zebra example): [GITHUB](https://github.com/tensorflow/tcav/blob/master/Run_TCAV.ipynb)\n",
        "  * [TCAV in CAPTUM](https://github.com/meta-pytorch/captum/blob/master/tutorials/TCAV_Image.ipynb)"
      ],
      "metadata": {
        "id": "f9bkxY2s5yIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Influencial example:\n",
        "  * Code example: [GITHUB](https://github.com/meta-pytorch/captum/blob/master/tutorials/TracInCP_Tutorial.ipynb)"
      ],
      "metadata": {
        "id": "tHSqyfWm7-vy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Sequence data (text) with recurrent networks\n",
        "* [SHAP (deepexplainer) for text analysis (sentiment analysis) with LSTM](https://shap.github.io/shap/notebooks/deep_explainer/Keras%20LSTM%20for%20IMDB%20Sentiment%20Classification.html)\n",
        "\n",
        "6. Time-series data with recurrent networks ([Journal Article](https://arxiv.org/abs/2104.00950))\n",
        "\n",
        "* Time-series data with recurrent networks\n",
        "  * Ths is the least developed area compared to the other type of data sets/networks (there is more on natural langugae processing (text seqeunces) and computer vision (image sequences) sequence data- but less for time-series data)\n",
        "  * **Post-hoc**: [TimeSHAP: for time-series data using LSTM](https://github.com/feedzai/timeshap/blob/main/notebooks/AReM/AReM_TF.ipynb) | [Manuscript](https://arxiv.org/pdf/2012.00073)\n",
        "* Use [CNN for time-series data](https://stefan-jansen.github.io/machine-learning-for-trading/18_convolutional_neural_nets/#code-example-cnn-ta---clustering-financial-time-series-in-2d-image-format)  and use post-hoc XAI suitable for CNN\n",
        "  * [Example 1: CNN + posthoc Gradient*Inputâ€™ method](https://arxiv.org/pdf/2004.12538)\n",
        "  * [Example 2: ConvTimeNet + post-hoc Occlusion](https://arxiv.org/abs/1904.12546)\n",
        "* **Antehoc methods**: refer to including interpretablity into model design (this is the opposite of posthoc methods, which lecture slides focussed)\n",
        "  * Use of attention mechanism with LSTM\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ucVwu75Zo-Sp"
      }
    }
  ]
}