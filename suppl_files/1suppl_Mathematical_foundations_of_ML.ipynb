{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNzXHx7dCnV1J62PZb/VcSM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaitragopalappa/MIE590-690D/blob/main/suppl_files/1suppl_Mathematical_foundations_of_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Math foundations**\n",
        "* Random variables\n",
        "  * Discrete RV\n",
        "  * Continuous RV\n",
        "  * Sigmoid (logistic) function\n",
        "  * Softmax function\n",
        "* Linear algebra\n",
        "  * Vector, matrix, tensor\n",
        "  * Vector spaces\n",
        "  * Norms of vector and matrix\n",
        "  * Matrix multiplication\n",
        "  * Matrix inversion\n",
        "* Matrix calculus\n",
        "  * Derivatives\n",
        "  * Gradients\n",
        "  * Jacobian\n",
        "  * Hessian\n",
        "* Optimization\n",
        "  * First-order methods (descent direction, stepsize, convergence rate)\n",
        "  * Stochastic gradient descent\n"
      ],
      "metadata": {
        "id": "txu9wHisEwFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Random Variable (RV)**\n",
        "[Chapter 2 of PML: A introduction by Murphy](https://probml.github.io/pml-book/book1.html)\n",
        "Let $X$ = number on roll of dice.   \n",
        "Value of $X$ is unknown and/or could change, and is thus a **random variable** or RV.   \n",
        "The set of possible values of $X$ is known as the **sample space or state space**.   \n",
        "An **event** is a set of outcomes from a given sample space. For example,   \n",
        "* the event of “seeing a 1” is $X$ = 1,\n",
        "*the event of “seeing an odd number” is denoted $X$ ∈ {1, 3, 5},\n",
        "*the event of “seeing a number between 1 and 3” is denoted 1 ≤ $X$ ≤ 3, etc.\n",
        "\n",
        "The function $𝐹$ is a cumulative distribution function (cdf) for a random variable $X$ if  $𝐹(𝑎)=Pr⁡(𝑋≤𝑎)$ for all real numbers $𝑎$.  \n",
        "The function $𝑓$ is the probability mass function of the discrete random variable $X$ if $𝑓(𝑘)=Pr(𝑋=𝑘)$.  \n",
        "The function $𝑔$ is called the probability density function (pdf) of the continuous random variable $𝑌$ if  $∫_{𝑎}^{𝑏} 𝑔(𝑢)𝑑𝑢=Pr⁡{(𝑎≤𝑌≤𝑏)}$ for all $𝑎,𝑏$ in the range of $𝑌$.\n"
      ],
      "metadata": {
        "id": "dr59kaWqEoYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Optimization**\n",
        "[Chapter 8 of PML: A introduction by Murphy](https://probml.github.io/pml-book/book1.html)\n",
        "### General optimization context\n",
        "**Objective**:* $Min  f(\\mathbf{x}); \\mathbf{x}\\in R^n $  *\n",
        "**Decision variables**: vector $\\mathbf{x}$  \n",
        "**Solution algorithm**: There are multiple algorithms, analytical and numerical, suitability is based on problem type. Gradient descent (GD) or steepest descent is a numerical optimization algorithm extensively used in ML\n",
        "\n"
      ],
      "metadata": {
        "id": "C0CnDjhhQjsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Numerical methods overview**\n",
        "Main transformation: $\\mathbf{x}_{t+1} = \\mathbf{x}_t − η_t p_\\mathbf{x}$  \n",
        "  * $η_t $ is step-size\n",
        "  * $p_\\mathbf{x}$  is search direction  \n",
        "\n",
        "Steps of solution algorithm:  \n",
        "1. Initialize $\\mathbf{x}_{t}$ for $t=0$ to a random value\n",
        "2. Estimate $\\mathbf{x}_{t+1} = \\mathbf{x}_t − η_t p_\\mathbf{x}$   \n",
        "3. If $|\\mathbf{x}_{t-1} - \\mathbf{x}_{t}| < ϵ $ stop, else goto 2.  "
      ],
      "metadata": {
        "id": "l5GhU5wn9xs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Gradient descent (GD)**\n",
        "(Also called vanilla gradient descent or steepest descent )  \n",
        "Main transformation:   \n",
        "$\\mathbf{x}_{t+1} = \\mathbf{x}_t − η_t∇_\\mathbf{x}f(\\mathbf{x}_t)$  \n",
        "  That is, the direction of search is the gradient $∇_\\mathbf{x}f(\\mathbf{x})$.   \n",
        "[Steepest descent demo](https://colab.research.google.com/github/probml/pyprobml/blob/master/notebooks/book1/08/steepestDescentDemo.ipynb)"
      ],
      "metadata": {
        "id": "90ILVxtj9MRl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Stochastic gradient descent (SGD)**\n",
        "Suppose there is noise in data, i.e.,\n",
        "\n",
        " $Min   \\mathbb {E}_{q(z)} [f(\\mathbf{x}, z)]; \\mathbf{x}\\in R^n $  \n",
        "  $z$ is 'noise' and $q(z)$ is its distribution function.\n",
        "  Then it is found that we can approximate\n",
        "$\\mathbf{x}_{t+1} = \\mathbf{x}_t − η_t∇_{\\mathbf{x}}f(\\mathbf{x}_t,z) = \\mathbf{x}_t −  η_t∇_{\\mathbf{x}}f(\\mathbf{x}_t)$ under conditions that distribution of noise $(q(z))$ is independent of the paramters we are optimizing, and we can calculate the unbiased estimate of the gradient of $L$\n"
      ],
      "metadata": {
        "id": "ZbhdrHKpaeAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Optimization- context of machine learning**\n",
        "* Objective\n",
        "* Train and test data\n",
        "* Data Batching for training\n",
        "* Optimizers"
      ],
      "metadata": {
        "id": "UTxxY77R2CLU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Objective function**\n",
        "Suppose ${\\mathbf{y}}=f(\\mathbf{{x}});\\mathbf{x}\\in \\mathbb{R}^n; \\mathbf{y}\\in\\mathbb{R}^m$  \n",
        "Objective: $ \\mathcal{L} =Min_{\\mathbf{\\theta}}||\\mathbf{\\hat{y}-y}||$  \n",
        "* $\\mathcal{L} $ is called the loss function   \n",
        "* $\\mathbf{\\hat{y}}$ are the predicted values using a ML model  \n",
        "* $ {\\mathbf{\\theta}}$ are the co-efficients of the ML model that we are aiming to solve, i.e., find ${\\mathbf{\\theta}}$ that minimizes $\\mathcal{L}$\n"
      ],
      "metadata": {
        "id": "4soHT_Ts_jA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train and test sets**\n",
        "* Typical to split data into train and test sets\n",
        "* Use ‘train’ set to train the data\n",
        "* Test the trained model on the ‘test’ set\n"
      ],
      "metadata": {
        "id": "o8Ogoo6qE1gh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Batching of train set**\n",
        "* Batch: use the full train set to train the model\n",
        "* Mini-batch: divide train set into small mini-batches\n",
        "  * Typically $2^𝑛$: 32, 64, 128, 256 (corresponding to CPU /GPU architecture)\n",
        "* Incremental/ online learning: single sample at a time\n",
        "\n",
        "Bengio, Practical recommendations for gradient-based training of deep architectures, 2012, https://arxiv.org/abs/1206.5533\n",
        "\n"
      ],
      "metadata": {
        "id": "yDiw8XyW3wh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Optimizers in ML - SDG and variants**\n",
        "Different options for search direction and learning rate (step size)\n",
        "### Line search methods\n",
        "Methods that pick a search direction and step in that direction with some step size. In ML step-size are typically referred to as learing rate\n",
        "* Gradient as search direction\n",
        "  * SDG\n",
        "  * SDG with momentum\n",
        "  * SDG with Nestrov\n",
        "* Adaptive learning rate (step size)\n",
        "  * AdaGrad\n",
        "  * RMSProp\n",
        "  * Adam\n",
        "* Hessian as search direction\n",
        "  * Newtons method\n",
        "  * Conjugate gradients\n",
        "  * BFGS\n",
        "\n",
        "### Trust-region methods\n",
        "Methods that determine search direction and step-size together\n",
        "* Levenberg Marquardt\n",
        "\n",
        "### References\n",
        "[Algorithms](https://www.deeplearningbook.org/contents/optimization.html) Algorithms 8.1 to 8.7 from Chapter 8: Ian Goodfellow and Yoshua Bengio and Aaron Courville, Deep Learning  \n",
        "[Computational implementation in Pytorch](https://docs.pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD)"
      ],
      "metadata": {
        "id": "rvGZVAbh41tM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional variants\n",
        "\n",
        "New variants are continuoualy added- Best way to keep up is to look at NN libraries (Keras, Pytorch, Tensorflow) on available options\n",
        "* [Kieras](https://keras.io/api/optimizers/)  \n",
        "* [Pytorch](https://pytorch.org/docs/stable/optim.html)  \n",
        "* [Tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers )  \n",
        "\n",
        "Bengio, Practical recommendations for gradient-based training of deep architectures, 2012, https://arxiv.org/abs/1206.5533\n"
      ],
      "metadata": {
        "id": "VDw54tINMFEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convergence**\n",
        "Convergence and properties for convergence of the above algorithms [Slides](\n",
        "https://github.com/chaitragopalappa/MIE590-690D/blob/main/suppl_files/1b_Overview%20of%20convergence.pdf)"
      ],
      "metadata": {
        "id": "R6CHeCzMNLD_"
      }
    }
  ]
}