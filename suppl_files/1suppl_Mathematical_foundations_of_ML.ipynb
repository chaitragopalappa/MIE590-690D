{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsUYZpYLQtYsyNxOadMiA2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaitragopalappa/MIE590-690D/blob/main/suppl_files/1suppl_Mathematical_foundations_of_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Math foundations**\n",
        "Math foundations of machine learning include probability and statistics, linear algebra, multivariate calculus, and opimization. All but optimization are courses engineering students take in undergraduate degree and may have seen them throughout other courses. It is good to refresh on these topics. I have listed a few topics below that comes up frequently that you can start with, along with references. Optimization is not a course that all engineers take, but you would have come across these topics in Statistical Machine Learning, I have expanded on a few relevant concepts below.\n",
        "* [Random variables - Chapters 2.1 to 2.5 of PML: An Introduction, by Murphy](https://probml.github.io/pml-book/book1.html)\n",
        "  * Discrete RV\n",
        "  * Continuous RV\n",
        "  * Sigmoid (logistic) function\n",
        "  * Softmax function\n",
        "* [Linear algebra - Chapters 7.1 and 7.2 of PML: An Introduction, by Murphy](https://probml.github.io/pml-book/book1.html)\n",
        "  * Vector, matrix, tensor\n",
        "  * Vector spaces\n",
        "  * Norms of vector and matrix\n",
        "  * Matrix multiplication\n",
        "  * Matrix inversion\n",
        "* [Matrix calculus - Chapter 7.8 of PML: An Introduction, by Murphy](https://probml.github.io/pml-book/book1.html)\n",
        "  * Derivatives\n",
        "  * Gradients\n",
        "  * Jacobian\n",
        "  * Hessian\n",
        "* Optimization\n",
        "  * First-order methods (descent direction, stepsize, convergence rate)\n",
        "  * Stochastic gradient descent\n"
      ],
      "metadata": {
        "id": "txu9wHisEwFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Optimization**\n",
        "[Chapter 8 of PML: A introduction by Murphy](https://probml.github.io/pml-book/book1.html)\n",
        "### General optimization context\n",
        "**Objective** $Min  f(\\mathbf{x}); \\mathbf{x}\\in R^n $   \n",
        "**Decision variables**: vector $\\mathbf{x}$  \n",
        "**Solution algorithm**: We can solve this **analytically** or **numerically**; suitability is based on problem type. Gradient descent (GD) or steepest descent is a numerical optimization algorithm extensively used in ML\n",
        "\n"
      ],
      "metadata": {
        "id": "C0CnDjhhQjsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Optimization in context of Linear Regression\n",
        "\n",
        "\n",
        "Objective: $ \\mathcal{L} =Min_{\\mathbf{w}}||\\mathbf{\\hat{y}-y}||_2^2 $  \n",
        "* $\\mathcal{L} $ is  the loss function, which is minimizing the sum of square error between actual and predicted values\n",
        "* $\\mathbf{\\hat{y}}$ are the predicted values using a ML model  \n",
        "* $ {\\mathbf{w}}$ are the co-efficients of the ML model that we are aiming to solve, i.e., find ${\\mathbf{w}}$ that minimizes $\\mathcal{L}$\n",
        "\n",
        "Suppose our prediction model is lnear regression of the form\n",
        "$$\n",
        "\\hat{y} = w_0 + w_1 x_1 + w_2 x_2 + \\cdots + w_N x_N\n",
        "$$\n",
        "to  **m data points** $(x_i, y_i), \\; i=1,\\dots,m$, we minimize the **average loss** (sometimes called **cost function**), i.e.,\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(w_0, w_1,...) = \\frac{1}{m}\\sum_{i=1}^m \\big( y^{(i)} - (w_0 + w_1 x_1^{(i)}+w_2x_2^{(i)}+...+w_Nx_N^{(i)}) \\big)^2\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "mzheJLRRwMhu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression - Analytical Solution using first order derivatives:**\n",
        "\n",
        "Find  ${\\mathbf{w}}$ such that gradient of $ \\mathcal{L}$ is zero, i.e., $ \\frac{\\partial\\mathcal{L}}{\\partial w_j}=0;\\forall j$\n",
        "\n",
        "\n",
        "-  $ \\frac{\\partial\\mathcal{L}}{\\partial w_j}=\\frac{2}{m}\\sum_{i=1}^m \\big( y^{(i)} - (w_0 + w_1 x_1^{(i)}+w_2x_2^{(i)}+...+w_Nx_N^{(i)}) \\big)(x_j^{(i)})$, $\\forall j \\in {0,1,...,N}$, where\n",
        "  $x_0=1$\n",
        "\n",
        "**Matrix form**\n",
        "\n",
        "Suppose,  \n",
        "  $\n",
        "  X =\n",
        "  \\begin{bmatrix}\n",
        "  1 & x_{11} & x_{12} & \\cdots & x_{1N} \\\\\n",
        "  1 & x_{21} & x_{22} & \\cdots & x_{2N} \\\\\n",
        "  \\vdots & \\vdots & \\vdots & & \\vdots \\\\\n",
        "  1 & x_{m1} & x_{m2} & \\cdots & x_{mN}\n",
        "  \\end{bmatrix}\n",
        "  $ ; $\n",
        "  w = \\begin{bmatrix}\n",
        "  w_0 \\\\ w_1 \\\\ \\vdots \\\\ w_N\n",
        "  \\end{bmatrix}\n",
        "  $ ; $\n",
        "  y = \\begin{bmatrix}\n",
        "  y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_m\n",
        "  \\end{bmatrix}\n",
        "  $\n",
        "\n",
        "Then,   \n",
        "$\\nabla L_w(w) =  X^T X w - X^T y $\n",
        "\n",
        "At the point where the graidents are equal to zero, we have\n",
        "\n",
        "  $\n",
        "  X^T X w = X^T y\n",
        "  $  ;  \n",
        "  $\n",
        "  \\hat{w} = (X^T X)^{-1} X^T y\n",
        "  $  \n",
        "These are called **normal equations** because, at the optimal solution, $y − Xw$ is normal\n",
        "(orthogonal) to the range of $X$.\n"
      ],
      "metadata": {
        "id": "X1-kjZ2RupJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Numerical methods of optmization - Overview (Deep Learning mainly uses this)**\n",
        "Main transformation: $\\mathbf{x}_{t+1} = \\mathbf{x}_t − η_t p_\\mathbf{x}$  \n",
        "  * $η_t $ is step-size\n",
        "  * $p_\\mathbf{x}$  is search direction  \n",
        "\n",
        "Steps of solution algorithm:  \n",
        "1. Initialize $\\mathbf{x}_{t}$ for $t=0$ to a random value\n",
        "2. Estimate $\\mathbf{x}_{t+1} = \\mathbf{x}_t − η_t p_\\mathbf{x}$   \n",
        "3. If $|\\mathbf{x}_{t-1} - \\mathbf{x}_{t}| < ϵ $ stop, else goto 2.  "
      ],
      "metadata": {
        "id": "l5GhU5wn9xs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Gradient descent (GD)**\n",
        "(Also called vanilla gradient descent or steepest descent )  \n",
        "Main transformation:   \n",
        "$\\mathbf{x}_{t+1} = \\mathbf{x}_t − η_t∇_\\mathbf{x}f(\\mathbf{x}_t)$  \n",
        "  That is, the direction of search is the gradient $∇_\\mathbf{x}f(\\mathbf{x})$.   \n",
        "[Steepest descent demo](https://colab.research.google.com/github/probml/pyprobml/blob/master/notebooks/book1/08/steepestDescentDemo.ipynb)"
      ],
      "metadata": {
        "id": "90ILVxtj9MRl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Stochastic gradient descent (SGD)**\n",
        "Suppose there is noise in data, i.e.,\n",
        "\n",
        " $Min   \\mathbb {E}_{q(z)} [f(\\mathbf{x}, z)]; \\mathbf{x}\\in R^n $  \n",
        "  $z$ is 'noise' and $q(z)$ is its distribution function.\n",
        "  Then it is found that we can approximate\n",
        "$\\mathbf{x}_{t+1} = \\mathbf{x}_t − η_t∇_{\\mathbf{x}}f(\\mathbf{x}_t,z) = \\mathbf{x}_t −  η_t∇_{\\mathbf{x}}f(\\mathbf{x}_t)$ under conditions that distribution of noise $(q(z))$ is independent of the paramters we are optimizing, and we can calculate the unbiased estimate of the gradient of $L$\n"
      ],
      "metadata": {
        "id": "ZbhdrHKpaeAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Numerical optimization- context of machine learning**\n",
        "* Objective\n",
        "* Train and test data\n",
        "* Data Batching for training\n",
        "* Optimizers"
      ],
      "metadata": {
        "id": "UTxxY77R2CLU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train and test sets**\n",
        "* Typical to split data into train and test sets\n",
        "* Use ‘train’ set to train the data\n",
        "* Test the trained model on the ‘test’ set\n"
      ],
      "metadata": {
        "id": "o8Ogoo6qE1gh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Batching of train set**\n",
        "* Batch: use the full train set to train the model\n",
        "* Mini-batch: divide train set into small mini-batches\n",
        "  * Typically $2^𝑛$: 32, 64, 128, 256 (corresponding to CPU /GPU architecture)\n",
        "* Incremental/ online learning: single sample at a time\n",
        "\n",
        "Bengio, Practical recommendations for gradient-based training of deep architectures, 2012, https://arxiv.org/abs/1206.5533\n",
        "\n"
      ],
      "metadata": {
        "id": "yDiw8XyW3wh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression - Gradient methods (numerical methods of optimzation)"
      ],
      "metadata": {
        "id": "KIBYc-rKwGNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objective Function for Linear Regression\n",
        "To fit a linear regression model of the form\n",
        "$$\n",
        "y = w_0 + w_1 x_1 + w_2 x_2 + \\cdots + w_N x_N\n",
        "$$\n",
        "to  **m data points** $(x_i, y_i), \\; i=1,\\dots,m$, we minimize the **average loss** (sometimes called **cost function**), i.e.,\n",
        "$$\n",
        "Min_w \\mathcal{L}(w_0, w_1,...) $$\n",
        "$$\n",
        "\\mathcal{L}(w_0, w_1,...) =  \\frac{1}{m}\\sum_{i=1}^m \\big( y^{(i)} - (w_0 + w_1 x_1^{(i)}+w_2x_2^{(i)}+...+w_Nx_N^{(i)}) \\big)^2\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "V8rR8hJw8iAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression - Gradient Descent (refers to batch training) and SGD (mini-batch or incremental training)\n",
        "**Gradient Descent(batch training because we are using all m datapoints in each iteration):**\n",
        "1. Initialize weights $\\mathbf{w_{t=0}}$ (iteration $t=0$;) Set learning rate η\n",
        "2. Calculate gradients at the point  $\\mathbf{w}$ (using **all m datapoints**)  \n",
        "$ \\frac{\\partial\\mathcal{L}}{\\partial w_j}=\\frac{2}{m}\\sum_{i=1}^m \\big( y^{(i)} - (w_0 + w_1 x_1^{(i)}+w_2x_2^{(i)}+...+w_Nx_N^{(i)}) \\big)(x_j^{(i)})$\n",
        "3. Update weights  \n",
        "$\\mathbf{w}_{t+1} = \\mathbf{w}_t − η∇_\\mathbf{w}\\mathcal{L}(\\mathbf{w}_t)$   \n",
        "$∇_\\mathbf{w}\\mathcal{L}(\\mathbf{w}) =[\\frac{\\partial\\mathcal{L}}{\\partial w_0} \\frac{\\partial\\mathcal{L}}{\\partial w_1} ..... \\frac{\\partial\\mathcal{L}}{\\partial w_N}]^T$\n",
        "4. If gradient < tolerance stop, else go to step 2.  \n",
        "\n",
        "**Stochastic Gradient Descent(using mini-batch training adds gradient noise)**\n",
        "1. Initialize weights $\\mathbf{w_{t=0}}$ (**epoch** $t=0$;) Set learning rate η\n",
        "2. For $b= 1$ to $B$ (**B is number of minibatches** each with size $m_b$)(typically reshuffled every epoch to avoid overfitting)\n",
        "  * Calculate gradients at the point  $\\mathbf{w}$  \n",
        "  $ \\frac{\\partial\\mathcal{L}}{\\partial w_j}=\\frac{2}{m_b}\\sum_{i=1}^{m_b} \\big( y^{(i)} - (w_0 + w_1 x_1^{(i)}+w_2x_2^{(i)}+...+w_Nx_N^{(i)}) \\big)(x_j^{(i)})$\n",
        "  * Update weights  \n",
        "   $\\mathbf{w}_{t+1} = \\mathbf{w}_t − η∇_\\mathbf{w}\\mathcal{L}(\\mathbf{w}_t)$   \n",
        "  $∇_\\mathbf{w}\\mathcal{L}(\\mathbf{w}) =[\\frac{\\partial\\mathcal{L}}{\\partial w_0} \\frac{\\partial\\mathcal{L}}{\\partial w_1} ..... \\frac{\\partial\\mathcal{L}}{\\partial w_N}]^T$\n",
        "4. If gradient < tolerance stop, else go to step 2.  \n",
        "\n",
        "**Stochastic Gradient Descent(using incremental training)**\n",
        "Same as mini-batch with batch size = 1. Useful for online training when we have only sample at a time.\n"
      ],
      "metadata": {
        "id": "bR_SpfIlpFij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Optimizers in ML - SDG and variants**\n",
        "Different options for search direction and learning rate (step size)\n",
        "### Line search methods\n",
        "Methods that pick a search direction and step in that direction with some step size. In ML step-size are typically referred to as learing rate\n",
        "* Gradient as search direction\n",
        "  * SDG\n",
        "  * SDG with momentum\n",
        "  * SDG with Nestrov\n",
        "* Adaptive learning rate (step size)\n",
        "  * AdaGrad\n",
        "  * RMSProp\n",
        "  * Adam\n",
        "* Hessian as search direction\n",
        "  * Newtons method\n",
        "  * Conjugate gradients\n",
        "  * BFGS\n",
        "\n",
        "### Trust-region methods\n",
        "Methods that determine search direction and step-size together\n",
        "* Levenberg Marquardt\n",
        "\n",
        "### References\n",
        "[Algorithms](https://www.deeplearningbook.org/contents/optimization.html) Algorithms 8.1 to 8.7 from Chapter 8: Ian Goodfellow and Yoshua Bengio and Aaron Courville, Deep Learning  \n",
        "[Computational implementation in Pytorch](https://docs.pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD)"
      ],
      "metadata": {
        "id": "rvGZVAbh41tM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional variants\n",
        "\n",
        "New variants are continuoualy added- Best way to keep up is to look at NN libraries (Keras, Pytorch, Tensorflow) on available options\n",
        "* [Kieras](https://keras.io/api/optimizers/)  \n",
        "* [Pytorch](https://pytorch.org/docs/stable/optim.html)  \n",
        "* [Tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers )  \n",
        "\n",
        "Bengio, Practical recommendations for gradient-based training of deep architectures, 2012, https://arxiv.org/abs/1206.5533\n"
      ],
      "metadata": {
        "id": "VDw54tINMFEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convergence**\n",
        "Convergence and properties for convergence of the above algorithms [Slides](\n",
        "https://github.com/chaitragopalappa/MIE590-690D/blob/main/suppl_files/1b_Overview%20of%20convergence.pdf)"
      ],
      "metadata": {
        "id": "R6CHeCzMNLD_"
      }
    }
  ]
}